{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnvRcpvhANCWFtVGQ5QrFp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eleven111101/GenAI_JPN11/blob/main/GENAI_JAPAN_POC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0pRHcBkveVJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04df6fb5-18e0-4752-cf90-8acbe410b9ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.4.0)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless\n",
        "!pip install pytesseract\n",
        "!pip install pdf2image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import re\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "# Install Poppler\n",
        "!apt-get install poppler-utils\n",
        "\n",
        "# Update PATH environment variable\n",
        "os.environ[\"PATH\"] += os.pathsep + \"/usr/bin/python3\"\n",
        "\n",
        "def extract_text_from_images(pdf_path):\n",
        "    text = \"\"\n",
        "\n",
        "    # Convert PDF pages to images using pdf2image\n",
        "    pages = convert_from_path(pdf_path, 300)  # Set the DPI (dots per inch)\n",
        "\n",
        "    for i, page in enumerate(pages, start=1):\n",
        "        # Save the image temporarily\n",
        "        temp_image_path = f\"temp_page_{i}.png\"\n",
        "        page.save(temp_image_path, \"PNG\")\n",
        "\n",
        "        # Read the saved image using OpenCV\n",
        "        img = cv2.imread(temp_image_path)\n",
        "\n",
        "        # Convert image to grayscale\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply thresholding to preprocess the image\n",
        "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Use pytesseract to perform OCR on the preprocessed image\n",
        "        img_text = pytesseract.image_to_string(thresh)\n",
        "\n",
        "        # Apply regular expression to extract text from the image text\n",
        "        extracted_text = re.findall(r'[A-Za-z0-9]+', img_text)\n",
        "        text += f\"Page {i}:\\n{' '.join(extracted_text)}\\n\\n\"\n",
        "\n",
        "        # Remove the temporary image file\n",
        "        os.remove(temp_image_path)\n",
        "\n",
        "    return text\n",
        "\n",
        "try:\n",
        "    # Ask the user for the input PDF file\n",
        "    pdf_path = input(\"Enter the path to the PDF file: \")\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(pdf_path):\n",
        "        print(\"Error: The specified file does not exist.\")\n",
        "    else:\n",
        "        # Extract text from images in the PDF\n",
        "        extracted_text = extract_text_from_images(pdf_path)\n",
        "\n",
        "        # Print the extracted text\n",
        "        print(extracted_text)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaLpYZyfTELW",
        "outputId": "02feb983-099e-466e-ce97-fff6d39cccdc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.3 [186 kB]\n",
            "Fetched 186 kB in 1s (254 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.3) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Enter the path to the PDF file: /content/Jyotiraditya_Parihar_Resume ASHWA (1).pdf\n",
            "An error occurred: [Errno 20] Not a directory: 'tesseract'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install tesseract-ocr\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqiD6N3ETzZX",
        "outputId": "57211047-9e46-43bf-dfa2-2a84849559bf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 0s (11.6 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 121782 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import re\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "# Add Poppler binaries to the PATH\n",
        "os.environ[\"PATH\"] += os.pathsep + \"/usr/bin\"\n",
        "\n",
        "def extract_text_from_images(pdf_path):\n",
        "    text = \"\"\n",
        "\n",
        "    # Convert PDF pages to images using pdf2image\n",
        "    pages = convert_from_path(pdf_path, 300)  # Set the DPI (dots per inch)\n",
        "\n",
        "    for i, page in enumerate(pages, start=1):\n",
        "        # Save the image temporarily\n",
        "        temp_image_path = f\"temp_page_{i}.png\"\n",
        "        page.save(temp_image_path, \"PNG\")\n",
        "\n",
        "        # Read the saved image using OpenCV\n",
        "        img = cv2.imread(temp_image_path)\n",
        "\n",
        "        # Convert image to grayscale\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply thresholding to preprocess the image\n",
        "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Use pytesseract to perform OCR on the preprocessed image\n",
        "        img_text = pytesseract.image_to_string(thresh)\n",
        "\n",
        "        # Apply regular expression to extract text from the image text\n",
        "        extracted_text = re.findall(r'[A-Za-z0-9]+', img_text)\n",
        "        text += f\"Page {i}:\\n{' '.join(extracted_text)}\\n\\n\"\n",
        "\n",
        "        # Remove the temporary image file\n",
        "        os.remove(temp_image_path)\n",
        "\n",
        "    return text\n",
        "\n",
        "try:\n",
        "    # Ask the user for the input PDF file\n",
        "    pdf_path = input(\"Enter the path to the PDF file: \")\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(pdf_path):\n",
        "        print(\"Error: The specified file does not exist.\")\n",
        "    else:\n",
        "        # Extract text from images in the PDF\n",
        "        extracted_text = extract_text_from_images(pdf_path)\n",
        "\n",
        "        # Print the extracted text\n",
        "        print(extracted_text)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztuf1F5mT2GX",
        "outputId": "1ad8f34c-0dda-44a1-f211-02ac51f98d63"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to the PDF file: /content/Jyotiraditya_Parihar_Resume ASHWA (1).pdf\n",
            "Page 1:\n",
            "Deori Maharashtra 441901 Jyotiraditya Parihar iotradityaparnar gmailcom WORK PROFILE OVERVIEW TCS Project Intern Nissan Project Simulation Engineer Responsibilities Worked as a Simulation Engineer for open scenarios in Advanced Driver Assistance Systems ADAS on ES Mini player Specifically focused on Automatic Emergency Brakes AEB implementation and optimization within the project using Automated Driving Toolbox and Road Runner on MATLAB Developed simulations for pedestrian scenarios and anti car collision systems as part of the project The Ashwa Riders CAE Lead CFO SAE BAJA ATV Racing Team Responsibilities Conducted linear and non linear analysis on vehicle components using Altair HyperWorks including stress modal and crash analysis using OptiStruct and RADIOSS solvers obtaining crucial performance data of ATV Achieved a weight reduction in the chassis from 32 58 kg to 29 5 kg resulting in a reduction of approximately 9 45 in weight Achieved weight reduction in arms of an ATV by up to 30 through material changes parameter optimization El Systems IIT Varanasi BHU Python Data Science Internship Responsibilities Extracted essential columns States Region and Estimated Unemployment Rate to compose the Unemployment DataFrame Crafted a hierarchical sunburst chart using Plotly Express px sunburst to visualize regional and state level unemployment data Configured sunburst chart dimensions at 700x700 pixels employing RdYIGn color scale to emphasize rates entitled Unemployment Rate in India Implemented dataset partitioning with test size 0 40 resulting in four datasets X train X test y train and y test for analysis purposes EDUCATION St Vincent Pallotti College of Engineering Technology Nagpur B Tech in Computer Engineering Current Aggregate 82 05 Year of Completion 2024 Sri Chaitanya Kalashala Hyderabad Senior Secondary Class 12th Percentage 87 5 Year of Completion 2019 Shree Swaminarayan Gurukul International School Hyderabad Higher Secondary Class 10th Percentage 82 Year of Completion 2017 PROJECTS ADAS Simulation Engineering TCS Nissan Developed and validated virtual ADAS features as a Simulation Engineer for Advanced Driver Assistance Systems ADAS on the ES Mini player platform Utilized MATLAB tools such as the Automated Driving Toolbox and Road Runner to conduct simulations of pedestrian scenarios and automated braking systems Conducted research on various ADAS features including Adaptive Cruise Control ACC and Lane Keeping Assist LKA contributing to the advancement of ADAS technology Project Black Stallion The Ashwa Riders Led ATV dynamics optimization initiatives by conducting comprehensive linear and crash analysis using Altair HyperWorks Applied impulse time momentum equation for Static Structural analysis optimizing forces applied on the chassis Improved Factor of Safety FOS from 1 2 to 1 5 through crash analysis ensuring enhanced safety and durability of the ATV Worked with team of 25 motorsports enthusiast for developing and fabricating an off roader vehicle competing in BAJA SAE INDIA 2022 2023 2024 seasons Unemployment Analysis Python Programming IIT Varanasi Eisystems Engaged in collaborative efforts to analyze unemployment data using Python harnessing essential libraries like NumPy and Pandas for data manipulation and preprocessing Utilized the Random Forest algorithm to forecast unemployment trends leveraging its robustness and adaptability aiming for informed decision making to address unemployment challenges effectively Facial Recognition with YOLOv5 Major Project Implemented YOLOvS5 an advanced object detection model for precise facial recognition in a major project Utilized YOLOv5 s architecture for accurate facial feature extraction and recognition Trained deep neural networks to improve facial recognition performance demonstrating proficiency in advanced computer vision techniques TOOLS AND SOFTWARE Tools Scikit learn TensorFlow Plotly Express NumPy Pandas Matplotlib Tkinter Optistruct Radioss YOLOv5 Python Programming ADAS System and Features Software Altair hyperworks Microsoft Excel ES Mini MATLAB Python IDE ACHIEVEMENTS Internships CodeClause ElSystems IIT Varanasi Tata Consultancy Services TCS Certifications Python HackerRank Deep Learning Coursera BAJA SAE INDIA 2023 AIR 1 6 awards BAJA SAE INDIA 2024 AIR 5\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import re\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "# Add Poppler binaries to the PATH\n",
        "os.environ[\"PATH\"] += os.pathsep + \"/usr/bin\"\n",
        "\n",
        "def extract_text_from_images(pdf_path):\n",
        "    text = \"\"\n",
        "\n",
        "    # Convert PDF pages to images using pdf2image\n",
        "    pages = convert_from_path(pdf_path, 300)  # Set the DPI (dots per inch)\n",
        "\n",
        "    for i, page in enumerate(pages, start=1):\n",
        "        # Save the image temporarily\n",
        "        temp_image_path = f\"temp_page_{i}.png\"\n",
        "        page.save(temp_image_path, \"PNG\")\n",
        "\n",
        "        # Read the saved image using OpenCV\n",
        "        img = cv2.imread(temp_image_path)\n",
        "\n",
        "        # Convert image to grayscale\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply thresholding to preprocess the image\n",
        "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Use pytesseract to perform OCR on the preprocessed image\n",
        "        img_text = pytesseract.image_to_string(thresh)\n",
        "\n",
        "        # Apply regular expression to extract text from the image text\n",
        "        extracted_text = re.findall(r'[A-Za-z0-9]+', img_text)\n",
        "        text += f\"Page {i}:\\n{' '.join(extracted_text)}\\n\\n\"\n",
        "\n",
        "        # Remove the temporary image file\n",
        "        os.remove(temp_image_path)\n",
        "\n",
        "    return text\n",
        "\n",
        "def check_accuracy(expected_text, extracted_text):\n",
        "    expected_words = set(expected_text.lower().split())\n",
        "    extracted_words = set(extracted_text.lower().split())\n",
        "\n",
        "    common_words = expected_words.intersection(extracted_words)\n",
        "    accuracy = len(common_words) / len(expected_words) * 100\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "try:\n",
        "    # Ask the user for the input PDF file\n",
        "    pdf_path = input(\"Enter the path to the PDF file: \")\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(pdf_path):\n",
        "        print(\"Error: The specified file does not exist.\")\n",
        "    else:\n",
        "        # Extract text from images in the PDF\n",
        "        extracted_text = extract_text_from_images(pdf_path)\n",
        "\n",
        "        # Print the extracted text\n",
        "        print(extracted_text)\n",
        "\n",
        "        # Sample expected text (replace with your expected text)\n",
        "        expected_text = \"Sample expected text for checking accuracy.\"\n",
        "\n",
        "        # Check accuracy\n",
        "        accuracy = check_accuracy(expected_text, extracted_text)\n",
        "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2xfaSd0UToN",
        "outputId": "d5bd8066-dad9-4cb9-b210-34f0a2dd4a26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to the PDF file: /content/Jyotiraditya_Parihar_Resume ASHWA (1).pdf\n",
            "Page 1:\n",
            "Deori Maharashtra 441901 Jyotiraditya Parihar iotradityaparnar gmailcom WORK PROFILE OVERVIEW TCS Project Intern Nissan Project Simulation Engineer Responsibilities Worked as a Simulation Engineer for open scenarios in Advanced Driver Assistance Systems ADAS on ES Mini player Specifically focused on Automatic Emergency Brakes AEB implementation and optimization within the project using Automated Driving Toolbox and Road Runner on MATLAB Developed simulations for pedestrian scenarios and anti car collision systems as part of the project The Ashwa Riders CAE Lead CFO SAE BAJA ATV Racing Team Responsibilities Conducted linear and non linear analysis on vehicle components using Altair HyperWorks including stress modal and crash analysis using OptiStruct and RADIOSS solvers obtaining crucial performance data of ATV Achieved a weight reduction in the chassis from 32 58 kg to 29 5 kg resulting in a reduction of approximately 9 45 in weight Achieved weight reduction in arms of an ATV by up to 30 through material changes parameter optimization El Systems IIT Varanasi BHU Python Data Science Internship Responsibilities Extracted essential columns States Region and Estimated Unemployment Rate to compose the Unemployment DataFrame Crafted a hierarchical sunburst chart using Plotly Express px sunburst to visualize regional and state level unemployment data Configured sunburst chart dimensions at 700x700 pixels employing RdYIGn color scale to emphasize rates entitled Unemployment Rate in India Implemented dataset partitioning with test size 0 40 resulting in four datasets X train X test y train and y test for analysis purposes EDUCATION St Vincent Pallotti College of Engineering Technology Nagpur B Tech in Computer Engineering Current Aggregate 82 05 Year of Completion 2024 Sri Chaitanya Kalashala Hyderabad Senior Secondary Class 12th Percentage 87 5 Year of Completion 2019 Shree Swaminarayan Gurukul International School Hyderabad Higher Secondary Class 10th Percentage 82 Year of Completion 2017 PROJECTS ADAS Simulation Engineering TCS Nissan Developed and validated virtual ADAS features as a Simulation Engineer for Advanced Driver Assistance Systems ADAS on the ES Mini player platform Utilized MATLAB tools such as the Automated Driving Toolbox and Road Runner to conduct simulations of pedestrian scenarios and automated braking systems Conducted research on various ADAS features including Adaptive Cruise Control ACC and Lane Keeping Assist LKA contributing to the advancement of ADAS technology Project Black Stallion The Ashwa Riders Led ATV dynamics optimization initiatives by conducting comprehensive linear and crash analysis using Altair HyperWorks Applied impulse time momentum equation for Static Structural analysis optimizing forces applied on the chassis Improved Factor of Safety FOS from 1 2 to 1 5 through crash analysis ensuring enhanced safety and durability of the ATV Worked with team of 25 motorsports enthusiast for developing and fabricating an off roader vehicle competing in BAJA SAE INDIA 2022 2023 2024 seasons Unemployment Analysis Python Programming IIT Varanasi Eisystems Engaged in collaborative efforts to analyze unemployment data using Python harnessing essential libraries like NumPy and Pandas for data manipulation and preprocessing Utilized the Random Forest algorithm to forecast unemployment trends leveraging its robustness and adaptability aiming for informed decision making to address unemployment challenges effectively Facial Recognition with YOLOv5 Major Project Implemented YOLOvS5 an advanced object detection model for precise facial recognition in a major project Utilized YOLOv5 s architecture for accurate facial feature extraction and recognition Trained deep neural networks to improve facial recognition performance demonstrating proficiency in advanced computer vision techniques TOOLS AND SOFTWARE Tools Scikit learn TensorFlow Plotly Express NumPy Pandas Matplotlib Tkinter Optistruct Radioss YOLOv5 Python Programming ADAS System and Features Software Altair hyperworks Microsoft Excel ES Mini MATLAB Python IDE ACHIEVEMENTS Internships CodeClause ElSystems IIT Varanasi Tata Consultancy Services TCS Certifications Python HackerRank Deep Learning Coursera BAJA SAE INDIA 2023 AIR 1 6 awards BAJA SAE INDIA 2024 AIR 5\n",
            "\n",
            "\n",
            "Accuracy: 16.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import re\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "# Add Poppler binaries to the PATH\n",
        "os.environ[\"PATH\"] += os.pathsep + \"/usr/bin\"\n",
        "\n",
        "def extract_text_from_images(pdf_path):\n",
        "    text = \"\"\n",
        "\n",
        "    # Convert PDF pages to images using pdf2image\n",
        "    pages = convert_from_path(pdf_path, 300)  # Set the DPI (dots per inch)\n",
        "\n",
        "    for i, page in enumerate(pages, start=1):\n",
        "        # Save the image temporarily\n",
        "        temp_image_path = f\"temp_page_{i}.png\"\n",
        "        page.save(temp_image_path, \"PNG\")\n",
        "\n",
        "        # Read the saved image using OpenCV\n",
        "        img = cv2.imread(temp_image_path)\n",
        "\n",
        "        # Convert image to grayscale\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply thresholding to preprocess the image\n",
        "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Use pytesseract to perform OCR on the preprocessed image\n",
        "        img_text = pytesseract.image_to_string(thresh, config='--psm 6')  # PSM 6 for sparse text\n",
        "\n",
        "        # Apply regular expression to extract text from the image text\n",
        "        extracted_text = re.findall(r'[A-Za-z0-9]+', img_text)\n",
        "        text += f\"Page {i}:\\n{' '.join(extracted_text)}\\n\\n\"\n",
        "\n",
        "        # Remove the temporary image file\n",
        "        os.remove(temp_image_path)\n",
        "\n",
        "    return text\n",
        "\n",
        "def check_accuracy(expected_text, extracted_text):\n",
        "    expected_words = set(expected_text.lower().split())\n",
        "    extracted_words = set(extracted_text.lower().split())\n",
        "\n",
        "    common_words = expected_words.intersection(extracted_words)\n",
        "    accuracy = len(common_words) / len(expected_words) * 100\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "try:\n",
        "    # Ask the user for the input PDF file\n",
        "    pdf_path = input(\"Enter the path to the PDF file: \")\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(pdf_path):\n",
        "        print(\"Error: The specified file does not exist.\")\n",
        "    else:\n",
        "        # Extract text from images in the PDF\n",
        "        extracted_text = extract_text_from_images(pdf_path)\n",
        "\n",
        "        # Print the extracted text with proper formatting\n",
        "        print(extracted_text)\n",
        "\n",
        "        # Sample expected text (replace with your expected text)\n",
        "        expected_text = \"\"\"Sample expected text for checking accuracy.\"\"\"\n",
        "\n",
        "        # Check accuracy\n",
        "        accuracy = check_accuracy(expected_text, extracted_text)\n",
        "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpGAWQVGUssw",
        "outputId": "1aba9bce-0199-496e-d583-21752166f32b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to the PDF file: /content/Jyotiraditya_Parihar_Resume ASHWA (1).pdf\n",
            "Page 1:\n",
            "jyotiradityaparihar gmail com Jyotiraditya Parihar moma Deori Maharashtra 441901 Neen eee WORK PROFILE OVERVIEW TCS Project Intern Nissan Project Simulation Engineer Responsibilities Worked as a Simulation Engineer for open scenarios in Advanced Driver Assistance Systems ADAS on ES Mini player Specifically focused on Automatic Emergency Brakes AEB implementation and optimization within the project using Automated Driving Toolbox and Road Runner on MATLAB Developed simulations for pedestrian scenarios and anti car collision systems as part of the project The Ashwa Riders CAE Lead CFO SAE BAJA ATV Racing Team Responsibilities Conducted linear and non linear analysis on vehicle components using Altair HyperWorks including stress modal and crash analysis using OptiStruct and RADIOSS solvers obtaining crucial performance data of ATV Achieved a weight reduction in the chassis from 32 58 kg to 29 5 kg resulting in a reduction of approximately 9 45 in weight Achieved weight reduction in arms of an ATV by up to 30 through material changes parameter optimization El Systems IIT Varanasi BHU Python Data Science Internship Responsibilities Extracted essential columns States Region and Estimated Unemployment Rate to compose the Unemployment DataFrame Crafted a hierarchical sunburst chart using Plotly Express px sunburst to visualize regional and state level unemployment data Configured sunburst chart dimensions at 700x700 pixels employing RdYIGn color scale to emphasize rates entitled Unemployment Rate in India Implemented dataset partitioning with test size 0 40 resulting in four datasets X train X test y train and y test for analysis purposes EDUCATION St Vincent Pallotti College of Engineering Technology Nagpur B Tech in Computer Engineering Current Aggregate 82 05 Year of Completion 2024 Sri Chaitanya Kalashala Hyderabad Senior Secondary Class 12th Percentage 87 5 Year of Completion 2019 Shree Swaminarayan Gurukul International School Hyderabad Higher Secondary Class 10th Percentage 82 Year of Completion 2017 PROJECTS ADAS Simulation Engineering TCS Nissan Developed and validated virtual ADAS features as a Simulation Engineer for Advanced Driver Assistance Systems ADAS on the ES Mini player platform Utilized MATLAB tools such as the Automated Driving Toolbox and Road Runner to conduct simulations of pedestrian scenarios and automated braking systems Conducted research on various ADAS features including Adaptive Cruise Control ACC and Lane Keeping Assist LKA contributing to the advancement of ADAS technology Project Black Stallion The Ashwa Riders Led ATV dynamics optimization initiatives by conducting comprehensive linear and crash analysis using Altair HyperWorks Applied impulse time momentum equation for Static Structural analysis optimizing forces applied on the chassis Improved Factor of Safety FOS from 1 2 to 1 5 through crash analysis ensuring enhanced safety and durability of the ATV Worked with team of 25 motorsports enthusiast for developing and fabricating an off roader vehicle competing in BAJA SAE INDIA 2022 2023 2024 seasons Unemployment Analysis Python Programming IIT Varanasi Eisystems Engaged in collaborative efforts to analyze unemployment data using Python harnessing essential libraries like NumPy and Pandas for data manipulation and preprocessing Utilized the Random Forest algorithm to forecast unemployment trends leveraging its robustness and adaptability aiming for informed decision making to address unemployment challenges effectively Facial Recognition with YOLOv5 Major Project Implemented YOLOvS5 an advanced object detection model for precise facial recognition in a major project Utilized YOLOv5 s architecture for accurate facial feature extraction and recognition Trained deep neural networks to improve facial recognition performance demonstrating proficiency in advanced computer vision techniques TOOLS AND SOFTWARE Tools Scikit learn TensorFlow Plotly Express NumPy Pandas Matplotlib Tkinter Optistruct Radioss YOLOv5 Python Programming ADAS System and Features Software Altair hyperworks Microsoft Excel ES Mini MATLAB Python IDE ACHIEVEMENTS Internships CodeClause ElSystems IIT Varanasi Tata Consultancy Services TCS Certifications Python HackerRank Deep Learning Coursera BAJA SAE INDIA 2023 AIR 1 6 awards BAJA SAE INDIA 2024 AIR 5\n",
            "\n",
            "\n",
            "Accuracy: 16.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas openpyxl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7cG1T_NU_gH",
        "outputId": "d4ece89e-3bc1-49fc-a65a-47b965848e51"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import pytesseract\n",
        "import re\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "# Add Poppler binaries to the PATH\n",
        "os.environ[\"PATH\"] += os.pathsep + \"/usr/bin\"\n",
        "\n",
        "def extract_text_from_images(pdf_path):\n",
        "    extracted_data = []\n",
        "\n",
        "    # Convert PDF pages to images using pdf2image\n",
        "    pages = convert_from_path(pdf_path, 300)  # Set the DPI (dots per inch)\n",
        "\n",
        "    for i, page in enumerate(pages, start=1):\n",
        "        # Save the image temporarily\n",
        "        temp_image_path = f\"temp_page_{i}.png\"\n",
        "        page.save(temp_image_path, \"PNG\")\n",
        "\n",
        "        # Read the saved image using OpenCV\n",
        "        img = cv2.imread(temp_image_path)\n",
        "\n",
        "        # Convert image to grayscale\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply thresholding to preprocess the image\n",
        "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Use pytesseract to perform OCR on the preprocessed image\n",
        "        img_text = pytesseract.image_to_string(thresh, config='--psm 6')  # PSM 6 for sparse text\n",
        "\n",
        "        # Apply regular expression to extract text from the image text\n",
        "        extracted_text = re.findall(r'[A-Za-z0-9]+', img_text)\n",
        "\n",
        "        # Append extracted text to the list\n",
        "        extracted_data.append({\n",
        "            'Page': f\"Page {i}\",\n",
        "            'Text': ' '.join(extracted_text)\n",
        "        })\n",
        "\n",
        "        # Remove the temporary image file\n",
        "        os.remove(temp_image_path)\n",
        "\n",
        "    return extracted_data\n",
        "\n",
        "try:\n",
        "    # Ask the user for the input PDF file\n",
        "    pdf_path = input(\"Enter the path to the PDF file: \")\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(pdf_path):\n",
        "        print(\"Error: The specified file does not exist.\")\n",
        "    else:\n",
        "        # Extract text from images in the PDF\n",
        "        extracted_data = extract_text_from_images(pdf_path)\n",
        "\n",
        "        # Create a DataFrame from the extracted data\n",
        "        df = pd.DataFrame(extracted_data)\n",
        "\n",
        "        # Save the DataFrame to an Excel file\n",
        "        output_file = 'extracted_data.xlsx'\n",
        "        df.to_excel(output_file, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {output_file}.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOQ_88uuVDSC",
        "outputId": "5fad154e-6d1c-46bd-a270-b4cf4754cd8c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to the PDF file: /Image extraction.pdf\n",
            "Data extracted and saved to extracted_data.xlsx.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import pytesseract\n",
        "import re\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "# Add Poppler binaries to the PATH\n",
        "os.environ[\"PATH\"] += os.pathsep + \"/usr/bin\"\n",
        "\n",
        "def extract_text_from_images(pdf_path):\n",
        "    extracted_data = []\n",
        "\n",
        "    # Convert PDF pages to images using pdf2image\n",
        "    pages = convert_from_path(pdf_path, 300)  # Set the DPI (dots per inch)\n",
        "\n",
        "    for i, page in enumerate(pages, start=1):\n",
        "        # Save the image temporarily\n",
        "        temp_image_path = f\"temp_page_{i}.png\"\n",
        "        page.save(temp_image_path, \"PNG\")\n",
        "\n",
        "        # Read the saved image using OpenCV\n",
        "        img = cv2.imread(temp_image_path)\n",
        "\n",
        "        # Convert image to grayscale\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply thresholding to preprocess the image\n",
        "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Use pytesseract to perform OCR on the preprocessed image\n",
        "        img_text = pytesseract.image_to_string(thresh, config='--psm 6')  # PSM 6 for sparse text\n",
        "\n",
        "        # Split the extracted text into separate lines\n",
        "        extracted_lines = img_text.strip().split('\\n')\n",
        "\n",
        "        # Append extracted lines to the list\n",
        "        extracted_data.append({\n",
        "            'Image': f\"Image {i}\",\n",
        "            'Text': '\\n'.join(extracted_lines)\n",
        "        })\n",
        "\n",
        "        # Remove the temporary image file\n",
        "        os.remove(temp_image_path)\n",
        "\n",
        "    return extracted_data\n",
        "\n",
        "try:\n",
        "    # Ask the user for the input PDF file\n",
        "    pdf_path = input(\"Enter the path to the PDF file: \")\n",
        "\n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(pdf_path):\n",
        "        print(\"Error: The specified file does not exist.\")\n",
        "    else:\n",
        "        # Extract text from images in the PDF\n",
        "        extracted_data = extract_text_from_images(pdf_path)\n",
        "\n",
        "        # Create a DataFrame from the extracted data\n",
        "        df = pd.DataFrame(extracted_data)\n",
        "\n",
        "        # Save the DataFrame to an Excel file\n",
        "        output_file = 'extracted_data.xlsx'\n",
        "        df.to_excel(output_file, index=False)\n",
        "\n",
        "        print(f\"Data extracted and saved to {output_file}.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "txBS2SgRXaee"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}